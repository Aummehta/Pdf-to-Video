

# ğŸ“ EduVisionAI: PDF-to-Educational Video Generator

**EduVisionAI** is an AI-powered automation pipeline that transforms academic **PDF documents** into **professionally narrated educational videos**.
It extracts figures and diagrams, generates intelligent explanations using multimodal AI (Gemini), converts them to natural speech (Edge TTS), and compiles everything into a full HD video presentation using MoviePy.

---

## ğŸ“˜ Overview

Academic papers often contain complex diagrams and figures that are difficult to interpret for non-experts or visually impaired learners.
**EduVisionAI** aims to bridge this gap by automatically:

* Extracting visual elements (charts, graphs, diagrams) from PDFs,
* Generating concise, educational explanations using **Google Gemini AI**,
* Narrating those explanations with a **natural human-like voice** using **Microsoft Edge TTS**, and
* Compiling them into a **structured, professional video** for enhanced learning accessibility.

This project demonstrates the integration of **multimodal AI**, **speech synthesis**, and **automated video creation** into a single cohesive system.

---

## ğŸ§  Key Features

âœ… **Automated Image Extraction** â€“ Extracts figures and diagrams from academic PDFs using **PyMuPDF**.
âœ… **AI-Powered Explanations** â€“ Uses **Google Gemini 2.5 Flash (Vision Model)** to analyze and explain each image.
âœ… **Natural Voice Narration** â€“ Converts explanations into high-quality speech using **Microsoft Edge TTS**.
âœ… **Professional Video Generation** â€“ Combines visuals, narration, and captions using **MoviePy** and **PIL**.
âœ… **Educational Presentation Style** â€“ Includes title slide, figure numbers, clean formatting, and a thank-you end screen.
âœ… **Accessibility Enhancement** â€“ Makes academic visuals understandable for students, educators, and visually impaired learners.

---

## âš™ï¸ Workflow

The project runs as a **cell-by-cell pipeline** (in Jupyter Notebook):

| Step         | Description                                                                | Key Tool / Model        |
| ------------ | -------------------------------------------------------------------------- | ----------------------- |
| **Cell 2**   | Extracts all images from a given PDF                                       | PyMuPDF (fitz)          |
| **Cell 3**   | Generates AI explanations for each image                                   | Google Gemini 2.5 Flash |
| **Cell 4â€“5** | Skips text extraction and chunking (focuses only on image-based narration) | â€”                       |
| **Cell 6**   | Converts AI explanations to audio narration                                | Microsoft Edge TTS      |
| **Cell 8**   | Combines visuals, text, and audio into a professional MP4 video            | MoviePy & PIL           |

---

## ğŸ§© System Architecture

```
PDF Input
   â”‚
   â–¼
Image Extraction (PyMuPDF)
   â”‚
   â–¼
AI Explanation Generation (Gemini API)
   â”‚
   â–¼
Text & Audio Processing (LangChain + Edge TTS)
   â”‚
   â–¼
Video Assembly (MoviePy + PIL)
   â”‚
   â–¼
ğŸ¥ Final Educational Video Output
```

---

## ğŸ§° Technologies Used

| Component                | Technology              | Purpose                                       |
| ------------------------ | ----------------------- | --------------------------------------------- |
| **Programming Language** | Python 3.10             | Core implementation                           |
| **PDF Handling**         | PyMuPDF                 | Extracts images from PDF pages                |
| **AI Explanation Model** | Google Gemini 2.5 Flash | Vision-based image understanding              |
| **Text Management**      | LangChain               | Coordinates AI responses and processing       |
| **Audio Narration**      | Microsoft Edge TTS      | Converts text to natural-sounding speech      |
| **Video Generation**     | MoviePy, PIL            | Combines images, text overlays, and narration |
| **Development Platform** | Jupyter Notebook        | Sequential execution and debugging            |

---

## ğŸ¯ Output

* **Final File:** `professional_image_explanation_video.mp4`
* **Resolution:** Full HD (1920x1080)
* **Audio:** High-quality AAC narration
* **Includes:**

  * Title Slide
  * Individual Image Segments with Explanations
  * Synced Voiceover
  * End Slide with Credits

---

## ğŸ“š Example Use Case

* Upload a **research paper** or **technical document** containing diagrams.
* EduVisionAI automatically:

  1. Extracts the figures,
  2. Generates educational explanations,
  3. Narrates the content, and
  4. Produces a professional video presentation.

Perfect for:
ğŸ“ **Students** â€“ for understanding complex papers
ğŸ‘©â€ğŸ« **Teachers** â€“ for creating learning materials
ğŸ“– **Researchers** â€“ for academic video summaries
ğŸ§‘â€ğŸ¦¯ **Visually Impaired Learners** â€“ for accessible content delivery

---

## ğŸ”® Future Improvements

* ğŸŒ Multilingual narration support
* ğŸ§‘â€ğŸ« Integration of AI-based teaching avatars
* ğŸ•¹ï¸ Real-time adaptive streaming
* âš¡ GPU-accelerated video rendering
* ğŸ§  Reinforcement feedback for improved explanation accuracy

---

## ğŸ Conclusion

**EduVisionAI** demonstrates how multimodal AI can transform static academic content into dynamic, engaging educational videos.
By integrating visual understanding, natural narration, and automated video generation, this project paves the way for the next generation of **AI-powered educational accessibility tools**.

---

Would you like me to add a **â€œSetup & Installationâ€** section next (commands and steps to run it locally)? Itâ€™ll make your GitHub README complete and ready to publish.
